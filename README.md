## Hi there! I'm Gourav Kumar ğŸ‘‹

## ğŸš€ About Me
Iâ€™m currently working as a **Associate at Cognizant** with **2.5+ years** of professional experience. I hold a **B.Tech. degree from BIT Mesra** and have a strong interest in data engineering.
I bring hands-on expertise in Python, SQL, PySpark, and big data technologies like Apache Spark, Kafka, Hadoop, and Hive. Skilled in building scalable data pipelines using Azure services such as Data Factory, Synapse, Databricks, and ADLS Gen2.

I have practical experience in end-to-end real-time and batch data processing â€” from data ingestion to building insightful dashboards using Power BI. My strong understanding of data warehousing, data modeling, and cloud-based solutions allows me to deliver reliable, efficient, and business-driven data systems.

## ğŸ“‚ Projects
  
### 1. [Stream Processing Pipeline with SCD Type 2 Implementation ğŸ”—](https://github.com/GouravKr128/Stream_Processing_Pipeline_with_SCD_Type_2_Implementation)
<sub>Tech Stack - Spark Structured Streaming, Kafka, Azure Event Hubs, Azure Synapse Analytics, Faker, PySpark, Azure Databricks, ADLS Gen2, Key Vault.</sub>

### 2. [Real Time Data Processing Pipeline Using DLT ğŸ”—](https://github.com/GouravKr128/Real_Time_Data_Processing_Pipeline_Using_DLT)
<sub>Tech Stack - Delta Live Tables, Autoloader, Unity Catalog, PySpark, Spark SQL, Workflows (Jobs), Databricks SQL Dashboards.</sub>

### 3. [ADF Based OnPrem to Cloud Migration Pipeline ğŸ”—](https://github.com/GouravKr128/ADF_Based_OnPrem_to_Cloud_Migration_Pipeline)
<sub>Tech Stack - Azure Data Factory, ADLS Gen2, Azure SQL Database, Azure Synapse Analytics, Power BI.</sub>

### 4. [Netflix Batch Processing Pipeline with BI Dashboard ğŸ”—](https://github.com/GouravKr128/Netflix_Batch_Processing_Pipeline_with_BI_Dashboard)
<sub>Tech Stack - Azure Data Factory, ADLS Gen2, Databricks, PySpark, Unity Catalog, Delta Lake, Power BI.</sub>

### 5. [Incremental Data Processing Pipeline with SCD Type 1 Implementation ğŸ”—](https://github.com/GouravKr128/Incremental_Data_Processing_Pipeline_with_SCD_Type_1_Implementation)
</sub>Tech Stack - PySpark, Azure Data Factory, ADLS Gen2, Azure Synapse Analytics, Azure Databricks, Azure SQL Database, Unity Catalog, Power BI, Key Vaults.</sub>

## ğŸ› ï¸ Skills

| Category | Technologies |
|------------------------|-------------------------|
| **Programming Languages & Libraries** | Python, SQL, PySpark |
| **Big Data Tools & Frameworks** | Apache Spark, Spark Structured Streaming, Delta Live Tables, Kafka, Hadoop, Hive |
| **Azure Cloud Stack** | Azure Data Factory, ADLS Gen2, Azure Synapse Analytics, Azure Databricks, Azure SQL Database, Logic apps, Azure Event Hubs, Key Vault |
| **Data Engineering** | Data Warehousing, Data Modelling, ETL, Delta Lake |
| **Visualization & Version Control** | Power BI, Git, GitHub |


